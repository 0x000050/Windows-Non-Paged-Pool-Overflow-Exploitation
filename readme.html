<!DOCTYPE html>
<html>
<head>
<title>readme.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="table-of-contents">Table of Contents</h1>
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#named-pipes-introduction">Named-Pipes Introduction</a></li>
<li><a href="#exploitation">Exploitation</a>
<ul>
<li><a href="#spraying-the-non-paged-pool">Spraying the non-paged pool</a></li>
<li><a href="#memory-disclosurearbitrary-read">Memory Disclosure/Arbitrary Read</a>
<ul>
<li><a href="#complete-control-over-the-overflow-data">Complete control over the overflow data</a></li>
<li><a href="#limited-control-over-the-overflow-data-overflowing-nextentry">Limited control over the overflow data: Overflowing NextEntry</a></li>
</ul>
</li>
<li><a href="#arbitrary-write">Arbitrary Write</a></li>
<li><a href="#arbitrary-freeing-of-security_client_context-objects">Arbitrary Freeing of SECURITY_CLIENT_CONTEXT Objects</a></li>
<li><a href="#identifying-corrupted-pipes">Identifying Corrupted Pipes</a></li>
<li><a href="#leaking-the-contents-of-the-overflown-data">Leaking The Contents of the Overflown Data</a></li>
<li><a href="#adjusting-for-different-pool-overflow-categories">Adjusting For Different Pool Overflow Categories</a></li>
</ul>
</li>
<li><a href="#future-work">Future work</a></li>
<li><a href="#references">References</a></li>
</ul>
<h1 id="introduction">Introduction</h1>
<p>In this document we provide a series of techniques that can be used to exploit overflows in the non-paged pool on Windows. The techniques (ab)use the functionalities provided by the named pipe file system (npfs) to turn the overflow into arbitrary read/write and escalate privileges.</p>
<p>The following table shows the coverage provided by the present document over different overflow categories, which is based on the level of control over the:</p>
<ol>
<li>Overflow data. In other words, is the overflow composed by user data or &quot;random&quot; data? e.g. <code>memcpy(overflown_chunk, user_controlled_data, overflow_size)</code> vs <code>memset(overflown_chunk, 0, overflow_size)</code></li>
<li>Overflow size. <code>memcpy(overflown_chunk, input_buffer, user_controlled_size)</code> vs <code>memcpy(overflown_chunk, input_buffer, random_size)</code></li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Overflow Size Control</th>
<th style="text-align:center">No Overflow Size Control</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Overflow Data Control</strong></td>
<td style="text-align:center">✔</td>
<td style="text-align:center">✔</td>
</tr>
<tr>
<td><strong>No Overflow Data Control</strong></td>
<td style="text-align:center">✔</td>
<td style="text-align:center">✓</td>
</tr>
</tbody>
</table>
<p>Previously documented techniques on the topic fell primarily under the category &quot;Overflow Data Control &amp;&amp; Overflow Size Control&quot; and the goal of the research was to increase that coverage. For further discussion of the table above, see the &quot;Adjusting For Different Pool Overflow Categories&quot; chapter.</p>
<p>Now we will get into the concepts related to named pipes that would allow us to build the exploitation primitives.</p>
<h1 id="named-pipes-introduction">Named-Pipes Introduction</h1>
<p>Named pipes are an inter-process communication mechanism that allows two processes potentially belonging to different computers to share data. A brief description of its operations (for more information see [1]), a named pipe connection has the server end, which creates the pipe, and the client end, which connects to that pipe. When a named-pipe connection is established, the underlying driver creates two queues, one for each end, within the Context Control Block (CCB). The CCB in the context of the npfs, is an undocumented structure used to hold information about a particular server/client connection. Those queues that are found within the CCB store entries that are primarily related with data written by the other end or pending read operations by the current end. The structure used for the queue entries is the following:</p>
<pre class="hljs"><code><div><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">DATA_QUEUE_ENTRY</span> {</span>
    LIST_ENTRY NextEntry;
    _IRP* Irp;
    _SECURITY_CLIENT_CONTEXT* SecurityContext;
    <span class="hljs-keyword">uint32_t</span> EntryType;
    <span class="hljs-keyword">uint32_t</span> QuotaInEntry;
    <span class="hljs-keyword">uint32_t</span> DataSize;
    <span class="hljs-keyword">uint32_t</span> x;
    <span class="hljs-keyword">char</span> Data[];
}
</div></code></pre>
<p>Note: this is an undocumented structure, some information was obtained through <a href="https://reactos.org/">ReactOS</a></p>
<p>An overview of the fields and some of the mechanisms implemented by npfs:</p>
<p><strong>NextEntry</strong>: used to create a circular linked list with all the queued data entries. Entries are primarily related to read and write operations. One way of creating write operation entries is through the WriteFile API call and those entries are removed from the list when all of their data are read by a client (e.g. using the ReadFile). The list includes a sentinel node, which is stored within the CCB of the named pipe.</p>
<p align="center">
  <img src="././images/linkedlist.svg" />
</p>
<p><strong>SecurityContext</strong>:</p>
<pre class="hljs"><code><div>nt!_SECURITY_CLIENT_CONTEXT
   +0x000 SecurityQos      : _SECURITY_QUALITY_OF_SERVICE
   +0x010 ClientToken      : Ptr64 Void
   +0x018 DirectlyAccessClientToken : UChar
   +0x019 DirectAccessEffectiveOnly : UChar
   +0x01a ServerIsRemote   : UChar
   +0x01c ClientTokenControl : _TOKEN_CONTROL
</div></code></pre>
<p>This field enables the server end of a named pipe to impersonate the security context of a client. An overview of how it works:</p>
<ol>
<li>The client writes some data to the server queue.</li>
<li>A DATA_QUEUE_ENTRY is created and its SecurityContext is populated with the current security context of the client</li>
<li>Steps (1),(2) can be repeated, each time capturing the security context of the client</li>
<li>After the server attempts to perform a read operation (and if there was no previous call to the FSCTL_XXX=0x110044 operation, see below), the SecurityContext of the current entry will be stored in the CCB of the named pipe connection. Interestingly, this step is also performed in the peek operation.</li>
</ol>
<p>The server can then call the <code>ImpersonateNamedPipeClient</code> which will attempt to impersonate the security context stored in the CCB after step (4)</p>
<p>It is noted that npfs exposes two file system operations related to impersonation.</p>
<ol>
<li><em>FSCTL_XXX=0x11001C</em>: this is the operation called with ImpersonateNamedPipeClient. The underlying code appears to be an inlined-optimized version of NpImpersonate with specific arguments that enable the possibility of impersonation of the security context stored in the Ccb.</li>
<li><em>FSCTL_XXX=0x110044</em>: calls the NpImpersonate directly with specific arguments that cause the impersonation functionality to be permanently disabled for the given np connection. So step (4) above only works if there was no previous call to this operation.</li>
</ol>
<p><strong>EntryType</strong>:
Data entries can have different types which change the way data in the structure are treated. Two important types are buffered and unbuffered entries.</p>
<p><em>Buffered Entries:</em></p>
<p>The DATA_QUEUE_ENTRY allocated is big enough to hold the actual data of the request. Buffered entries are subject to the quota management mechanism which we will see later on and can be created through the regular WriteFile API call.</p>
<p align="center">
  <img src="./images/buffered.svg" />
</p>
<p><em>Unbuffered Entries:</em></p>
<p>The DATA_QUEUE_ENTRY allocated is big enough to hold the header without the data. The Irp related to the request is linked to the entry and references the actual data of the request. One way to create unbuffered entries is by calling the NpInternalWrite (FSCTL_XXX: 0x119FF8).</p>
<p align="center">
  <img src="./images/unbuffered.svg" />
</p>
<p><strong>Irp</strong>: the IRP associated with the DATA_QUEUE_ENTRY. Two of the cases where this field is populated are:</p>
<p>a) When we have unbuffered entries</p>
<p>b) When a buffered entry is created that its size exceeds the available pipe quota.</p>
<p><strong>QuotaInEntry</strong>:
This is a field used to denote the quota consumed by the particular entry. For unbuffered entries is 0. In buffered entries, it starts with the DataSize and decreases with every potentially partial read until its value is dropped to 0.</p>
<p><strong>DataSize</strong>:
This is the length of the user data associated with the current DATA_QUEUE_ENTRY</p>
<p><strong>x</strong>: this field is uninitialized in the entry creation, probably used for padding</p>
<p><strong>Quota management mechanism</strong>: allows the server-end of the communication channel to specify the maximum size of data the queues can hold. When that limit is exceeded:</p>
<ol>
<li>In blocking mode (PIPE_WAIT) the entry is created with QuotaInEntry set to the number of bytes available in the current queue. Then, after every read (not peek) operation on a buffered entry, the read size gets added to the QuotaInEntry of the stalled write. When the QuotaInEntry becomes equal to the DataSize, that signals that there is enough space to hold that entry in the pipe's quota and its associated irp gets completed.</li>
<li>In non-blocking mode (PIPE_NOWAIT), the operation will fail. (the number of written bytes will be equal to 0)</li>
</ol>
<h1 id="exploitation">Exploitation</h1>
<h2 id="spraying-the-non-paged-pool">Spraying the non-paged pool</h2>
<p>In the past, Alex Ionescu has documented in a <a href="https://www.alex-ionescu.com/?p=231">blogpost</a>[2] the use of buffered entries to spray the non-paged pool. Another way of spraying the non-paged pool is through the use of unbuffered entries. As we have seen before, unbuffered entries allow memory allocation with complete control over both the size and the data (e.g. no DATA_QUEUE_ENTRY headers). The fact that we have full control over the data give unbuffered entries some distinct advantages:</p>
<ol>
<li>They can be used with complete precision to forge data structures (e.g. when exploiting UAF issues)</li>
<li>The operation that involves a forged data structure might have to free the object at the end of its procedure. If our forged structure is not aligned at the beginning of a pool chunk, it will cause a bug check in most allocators (probably all allocators except LFH) during the free procedure.</li>
<li>Similarly with buffered entries, we can leak their addresses</li>
</ol>
<p>The following code can be used to create unbuffered entries:</p>
<pre class="hljs"><code><div><span class="hljs-comment">//create the pipe/file in FILE_FLAG_OVERLAPPED mode (blocking mode)</span>
NtFsControlFile(pipe_handle, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, &amp;isb, <span class="hljs-number">0x119FF8</span>, buf, sz, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>);
</div></code></pre>
<p>It is noted that unbuffered entries are created mainly through the <code>NpInternal*</code> functions and it's not certain whether those functionalities are meant to be exposed to userspace code. For example, <code>NpInternalTransceive</code> doesn't permit direct calls from userspace programs.</p>
<h2 id="memory-disclosurearbitrary-read">Memory Disclosure/Arbitrary Read</h2>
<h3 id="complete-control-over-the-overflow-data">Complete control over the overflow data</h3>
<ol>
<li>Establish an arbitrary read by using the overflow to rewrite the DATA_QUEUE_ENTRY headers and forge an unbuffered entry. This technique was first documented by Corentin Bayet and Paul Fariello in [3]. It is noted that this was also the first research documenting the use of named pipes to establish a read primitive.</li>
</ol>
<p>The forged entry would like like this:</p>
<pre class="hljs"><code><div>DATA_QUEUE_ENTRY:
 NextEntry=whatever;
 Irp=Forged IRP Address;
 SecurityContext=ideally 0;
 EntryType=1;
 QuotaInEntry=ideally 0;
 DataSize=arbitrary read size;
 x=whatever;
 
IRP-&gt;SystemBuffer = arbitrary read address
</div></code></pre>
<p>For convenience, we can set the Irp to a userspace address (and in the absence of SMAP), but that's not our only option.</p>
<p align="center">
  <img src="./images/arbitrary_read.svg" width="700px" />
</p>
<ol start="2">
<li>
<p>Disclose the memory adjacent to the overflown chunk by using the overflow to rewrite the DATA_QUEUE_ENTRY headers and forge a buffered entry with DataSize bigger than the original value. This technique appears to be first documented by @scwuaptx through a <a href="https://github.com/scwuaptx/CTF/tree/master/2020-writeup/hitcon/lucifer">HITCON CTF challenge</a> [4].</p>
<p>This technique can be used to leak pointers/heap metadata and other interesting data that could be found/placed after our DATA_QUEUE_ENTRY.</p>
<p>To make this work, the forged DATA_QUEUE_ENTRY should look like this:</p>
<pre class="hljs"><code><div>DATA_QUEUE_ENTRY:
 NextEntry=whatever;
 Irp=ideally 0;
 SecurityContext=ideally 0;
 EntryType=0;
 QuotaInEntry=ideally 0; //mostly irrelevent in case we use the peek operation
 DataSize=something bigger than the original size;
 x=whatever;
</div></code></pre>
</li>
</ol>
<p align="center">
  <img src="./images/memory_disclosure.svg" width="550px" />
</p>
<h3 id="limited-control-over-the-overflow-data-overflowing-nextentry">Limited control over the overflow data: Overflowing NextEntry</h3>
<p>There are some cases where we might have a limited set of characters in our disposal to overflow the memory with (e.g. <code>RtlZeroMemory(buffer, bufferlen+1)</code>). In those cases, we can overflow the Flink of a DATA_QUEUE_ENTRY and make it point to a location where we have full control over the data. We can then use the techniques previously described to establish the memory reads. In most supported 64 bit architectures we have to be careful to craft canonical addresses. When this is taken under consideration and assuming little endian architecture, one easy way to redirect the Flink to a controlled location is to overwrite the first couple of bytes, since that will make the DATA_QUEUE_ENTRY point to a memory location near the current entry. Then with proper heap grooming, we make that location contain the forged DATA_QUEUE_ENTRY for relative/arbitrary memory reads.</p>
<p>This technique is illustrated below:</p>
<p align="center">
  <img src="./images/ex_memory_disclosure.svg" />
</p>
<p>In this diagram, we assume that we got an overflow and managed to redirect the Flink to the Data part of the buffered DATA_QUEUE_ENTRY. (e.g. replace the first byte of a segment pool allocation entry with the byte <code>sizeof(DATA_QUEUE_ENTRY)%256</code>). We then use the memory disclosure technique described before to leak the data of &quot;heap chunk 2&quot;</p>
<p>After getting the layout above, what's left is to read <code>DataSize+DataSize1-sizeof(DATA_QUEUE_ENTRY)+n</code> after which we will be able to read <code>n</code> bytes from &quot;chunk 2&quot;. The DataSize2 should be at least <code>DataSize1-sizeof(DATA_QUEUE_ENTRY)+n</code></p>
<p>In practice, there is one more challenge before using this technique. After Windows 7, Microsoft implemented safe-unlinking in the LIST_ENTRY members. Based on that, after reading DataSize bytes, the overflown DATA_QUEUE_ENTRY will get removed from the queue and the Flink/Blink will be validated, which in our case will trigger a bug check (<code>entry-&gt;Flink-&gt;Blink!=entry</code>). Fortunately, we can perform a &quot;read-only&quot; operation on the pipe queue through the use of <code>PeekNamedPipe</code> and work around this issue.</p>
<p>So a practical approach to what we discussed here is:</p>
<ol>
<li>Groom the pool memory to ensure the overwritten Flink will be displaced to a memory location containing the forged DATA_QUEUE_ENTRY. The forged data entry will facilitate a relative memory disclosure. The Flink of the forged data entry should point to a memory location which the user can modify, like for example a userspace address.</li>
<li>Overflow the Flink. (with this approach we only have to trigger this step once)</li>
<li>Use PeekNamedPipe with size&lt;DataSize+DataSize2 to activate the first forged DATA_QUEUE_ENTRY and leak adjacent pool memory. Goal here is to leak some interesting pointers and bypass ASLR. A data entry is a perfect fit for our purpose.</li>
<li>Modify the contents of the specified userspace address to hold a forged DATA_QUEUE_ENTRY that facilitates the arbitrary read. Use PeekNamedPipe with <code>size=DataSize+DataSize2+n</code> to leak n bytes from the address set in the SystenBuffer of the IRP.</li>
<li>Repeat steps (3) or (4) as deemed necessary</li>
</ol>
<p>The approach discussed here is illustrated below:</p>
<p align="center">
  <img src="./images/ex_memory_disclosure_and_read.svg" />
</p>
<h2 id="arbitrary-write">Arbitrary Write</h2>
<p>Similarly with arbitrary read, establishing any sort of write primitive using named pipes became more difficult with the hardened LIST_ENTRY operations. On Windows 7 for example, it is possible to write a kernel address (queue sentinel node in Ccb) to an arbitrary location. We could have done it by forging a DATA_QUEUE_ENTRY, with its Flink set to the target address and then reading the whole data entry. That would cause the data entry to get unlinked from the list which would cause the execution of <code>dqe-&gt;Flink-&gt;Blink=dqe-&gt;Blink</code>. As a target address we could have potentially used the size field of a suitable gdi object.</p>
<p>Post-Windows 7, we have to follow a different strategy. Here we assume that we have already established the relative/arbitrary read primitive suggested in &quot;Limited control over the overflow data&quot; chapter. So the plan is to abuse the quota management mechanism we discussed earlier on to forge a DATA_QUEUE_ENTRY that simulates a stalled write, through which we forge an IRP that would establish the arbitrary write upon the completion of the IRP.</p>
<p>Now the biggest challenge is forging a valid IRP that would allow us to establish the arbitrary write upon completion. Since IRP is a complicated structure and is legitimately processed by the kernel (i.e. IofCompleteRequest) and not the npfs which was the case in the Arbitrary Read technique, we have to be precise. The simplest way i found to achieve that was to create an entry that contains an IRP, use the arbitrary read to read that IRP, modify the IRP to perform the arbitrary write and create an unbuffered entry* to hold the forged IRP. Then, with the forged IRP in place, we just make some room in the queue by reading some data and we should cause the completion of our forged IRP and thus establish the arbitrary write.</p>
<p>*: It's important to use an unbuffered entry to hold the forged IRP since it will most likely get deallocated by the end of the call to IofCompleteRequest.</p>
<p>The simulated stalled DATA_QUEUE_ENTRY and forged IRP could look like this:</p>
<pre class="hljs"><code><div>DATA_QUEUE_ENTRY:
 NextEntry.Flink=accessible address;
 Irp=Forged IRP Address;
 SecurityContext=ideally 0;
 EntryType=0;
 QuotaInEntry=0;
 DataSize=arbitrary write size;
 x=whatever;
 
Forged IRP:
 Flags=Flags|IRP_BUFFERED_IO|IRP_INPUT_OPERATION&amp;~IRP_DEALLOCATE_BUFFER;
 AssociatedIrp=Source Address;
 UserBuffer=Destination Address;
 ThreadListEntry.Flink-&gt;Blink==ThreadListEntry.Blink-&gt;Flink==&amp;ForgedIRPAddr-&gt;ThreadListEntry;
</div></code></pre>
<p>To summarize:</p>
<ol>
<li>Spray the memory with data queue entries</li>
<li>Use the steps laid out in the &quot;Limited control over the overflow data&quot; section to establish the relative/arbitrary read</li>
<li>After step (1), it's likely that an adjacent chunk that can be reached through our relative read will hold a data entry. Identify that chunk and its handle (e.g. unique identifier in the Userdata or bruteforce), and find its address (dqe-&gt;Flink-&gt;Blink).</li>
<li>Create a data entry on the identified handle that will have an IRP. I have tested this with buffered entry while on exceeded pipe quota but it should also work for unbuffered entries.</li>
<li>The new entry should be added to the data queue next to the leaked entry. Use the arbitrary read to find the address of the newly created entry (leaked_entry-&gt;Flink), its IRP address and finally the IRP data.</li>
<li>With access to the IRP we identify the associated ETHREAD/EPROCESS and the system process by following the ActiveProcessLinks. We then note down the token addresses of the current process and the system process.</li>
<li>Modify the IRP to enable the arbitrary write as shown above from the system token address to the current process token address with length=8.</li>
<li>Read DataSize bytes (8 in this case) to trigger the arbitrary write.</li>
</ol>
<h2 id="arbitrary-freeing-of-securityclientcontext-objects">Arbitrary Freeing of SECURITY_CLIENT_CONTEXT Objects</h2>
<p>This could be an alternative to arbitrary write for escalating privileges. As we have already seen, after each read operation on a data entry there will be an attempt to determine whether the current SecurityContext should be stored in the current Ccb or not. What's interesting for our purpose is the fact that in case the SecurityContext field of the DATA_QUEUE_ENTRY is populated, there would be a call to the NpFreeClientSecurityContext with argument one of the following two:</p>
<ol>
<li>the SecurityContext stored DATA_QUEUE_ENTRY in case the client impersonation is disabled as described in the intro.</li>
<li>the SecurityContext stored in the Ccb in case impersonation is enabled. Essentially clean up the old context before replacing it with the new one.</li>
</ol>
<p>The option (1) appears to be more more straightforward since it frees the security context found in the current entry instead of the previous one, but any of the two should be usable.</p>
<p>So a high-level overview of how this could potentially be exploited is to forge a SECURITY_CLIENT_CONTEXT structure that is impersonable by the server, holds elevated privileges but doesn't require special permissions to impersonate (e.g. see the <a href="https://docs.microsoft.com/en-us/windows/win32/api/namedpipeapi/nf-namedpipeapi-impersonatenamedpipeclient">remarks</a>).</p>
<p>Steps:</p>
<ol>
<li>The steps at the beginning should be similar to the arbitrary write process. first, we establish the relative/arbitrary read, leak irp data, find current thread/process and potentially other elevated tokens that would enable us to construct that special token that is impersonable without permissions.</li>
<li>Find the pipe handle and the address of an entry that is different from the one used to establish the read/free primitive. Let's call it pipe_handle_client/pipe_handle_server.</li>
<li>Create n entries writing into the pipe_handle_client</li>
<li>Start from the last entry and read its SecurityContext using the arbitrary read</li>
<li>Trigger the arbitrary free on the address acquired in step (4)</li>
<li>Spray unbuffered entries with the forged SECURITY_CLIENT_CONTEXT created in (1)</li>
<li>Use the arbitrary read to verify whether we managed to replace the memory pointed by the stored SecurityClient context in (4) with the forged SECURITY_CLIENT_CONTEXT</li>
<li>If that fails, go to the previous data entry (Blink) and repeat step (4). Entries for which we were unable to allocate our forged SCC should be considered corrupted and an attempt to read from them will most likely trigger a BSOD. That's why we start from the end of the list and move backward, we have n tries to allocate the forged structure.</li>
<li>Read all the entries in pipe_handle_server until at least one byte is read from the overwritten SecurityContext (no more than its DataSize). At that point, the ClientContext with the forged data should already be copied to the Ccb of the pipe.</li>
<li>Call ImpersonateNamedPipeClient on the pipe_handle_server</li>
</ol>
<p>In the limited time spent testing this, i was able to attach a forged token to a thread, but the forged _TOKEN structure had some inconsistencies that needed fixing (e.g. integrity checks and fields pointing at absolute addresses within the token itself). Nevertheless, with some effort it should be possible to escalate using this technique.</p>
<h2 id="identifying-corrupted-pipes">Identifying Corrupted Pipes</h2>
<p>In some cases, it's useful to have the ability to identify pipes with corrupted data entries. For example, when the overflow is caused by an integer overflow. (e.g. something similar with CVE-2020-17087)</p>
<p align="center">
  <img src="./images/corrupted.svg" />
</p>
<p>So we are now in the state shown in the diagram, we have the victim entry whose headers have been rewritten to facilitate the read/write primitive, but several data entries have been corrupted in the process. The problem here is that we normally don't know which pipe handle corresponds to the valid victim entry. One way to find it is to iterate over all the pipe handles and perform an operation that would verify that we are dealing with the victim entry (e.g. read operation that leaks next chunk data). In our instance, this is not a great approach as most operations on corrupted entries (e.g. read) will most likely cause a momentary change in the background image (i.e. cause BSOD). So we want to skip over them.</p>
<p>Two approaches to achieve that could be:</p>
<ol>
<li>Extract some of the headers of the data entry itself and validate their values. In practice, using the peek operation, we can extract the DataSize field as shown below:</li>
</ol>
<pre class="hljs"><code><div>PeekNamedPipe(pipe_handle, buf, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, &amp;remaining);
<span class="hljs-comment">//remaining=FirstEntry-&gt;DataSize-alreadyRead</span>
<span class="hljs-comment">//so if remaining=="AAAAAAAAAA" it's most likely corrupted</span>
</div></code></pre>
<ol start="2">
<li>Find a functionality in npfs that can work through a corrupted data entry, and its control flow/responses depend on the DATA_QUEUE_ENTRY headers. For example, by calling the operation that corresponds to the code <code>0x116000</code> with read length equal to 0, the NpReadDataQueue will follow different code paths based on the value of the EntryType. If the EntryType is greater than 1, then the <code>isb.Status</code> will be equal to 0 otherwise it will be 0x80000005 (note, there is also a semi-reliable timing channel that allows us to determine which path was taken):</li>
</ol>
<pre class="hljs"><code><div>NtFsControlFile(pipe_handle, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, <span class="hljs-number">0</span>, &amp;isb, <span class="hljs-number">0x116000</span>, buf, <span class="hljs-number">0</span>, buf, <span class="hljs-number">0</span>);
<span class="hljs-comment">//isb.Status==0?"corrupted":"good" (assuming the overflow written something different to 0,1)</span>
</div></code></pre>
<p>On the downside, there is a limitation with the examples provided above: they only work for pipes created with the PIPE_TYPE_MESSAGE flag. This is not ideal since in practice we are not able to use the Peek operation to go pass the first data entry and utilize the specially crafted Flink to activate our forged data entries (i.e. the approach used in &quot;Limited control over the overflow data&quot;).</p>
<p>This behavior of the peek operation is a bit counter-intuitive (maybe a bug?) since the read mode of the operation is normally based on the read mode of the pipe and not its type mode. This is actually true for the ReadFile (i.e. uses read mode) but not for the peek operation (uses the type mode). In the documentation of <a href="https://docs.microsoft.com/en-us/windows/win32/api/namedpipeapi/nf-namedpipeapi-peeknamedpipe">PeekNamedPipe</a> we see an attempt to explain this behavior (i.e. &quot;The data is read in the mode specified with CreateNamedPipe. For example, create a pipe with PIPE_TYPE_MESSAGE | PIPE_READMODE_MESSAGE. If you change the mode to PIPE_READMODE_BYTE with SetNamedPipeHandleState, ReadFile will read in byte mode, but PeekNamedPipe will continue to read in message mode&quot;). The problem is that this behavior remains even when the pipe is opened with &quot;PIPE_TYPE_MESSAGE | PIPE_READMODE_BYTE&quot;, which doesn't appear to be conforming with the documentation.</p>
<h2 id="leaking-the-contents-of-the-overflown-data">Leaking The Contents of the Overflown Data</h2>
<p>Other than spraying and forging data structures, unbuffered entries can also be used to leak the overflown data. This is true, since their chunks in memory are composed 100% by the user data, so there is no risk of corruption after the overflow (the pool header, if exists, it would still be corrupted). So after the overflow, the unbuffered entry will be filled with the overflow data which we should be able to read afterwards.</p>
<p>Potential use-cases:</p>
<ol>
<li>Leak potentially valuable information (e.g. interesting addresses)</li>
<li>If we control the overflow data, then that could be used potentially to determine some information about the LFH state (or not)</li>
<li>Let's say we are targeting the Low Fragmentation Heap (LFH) and we have the problem previously described with identifying corrupted pipes. We know that a subsegment can hold <code>x</code> objects of a target size and we also assume that subsegments are allocated sequentially. So we allocate <code>2*x</code> unbuffered entries and <code>1</code> buffered. We repeatedly induce the overflow (prerequisite is a reliable way of inducing the vulnerability) until the overflow hits one of the buffered entries. We then go sequentially with the allocation order through our pipes, read their contents and find the last unbuffered overflown entry (overflown_unbuffered_entry_index). The buffered entry allocated within the range of: <code>overflown_unbuffered_entry_index-x to overflown_unbuffered_entry_index+x</code> should be the <code>victim_entry</code></li>
<li>Maybe some other more practical usecases:)</li>
</ol>
<h2 id="approach-for-different-pool-overflow-categories">Approach For Different Pool Overflow Categories</h2>
<p>Now we will have a brief overview of how the discussed techniques could be used in different overflow scenarios. Let's revisit the table we've seen in the introduction:</p>
<table>
<thead>
<tr>
<th></th>
<th style="text-align:center">Overflow Size Control</th>
<th style="text-align:center">No Overflow Size Control</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Overflow Data Control</strong></td>
<td style="text-align:center">✔</td>
<td style="text-align:center">✔</td>
</tr>
<tr>
<td><strong>No Overflow Data Control</strong></td>
<td style="text-align:center">✔</td>
<td style="text-align:center">✓</td>
</tr>
</tbody>
</table>
<ol>
<li>
<p>Data Control/Size Control</p>
<p>This should be the easiest category of overflows to exploit. All of the techniques discussed here should be applicable.</p>
</li>
<li>
<p>Data Control/No Size Control</p>
<p>Again, theoretically it should be possible to use all techniques. The approach would be dependent on the exact overflow size and vulnerable chunk size.</p>
</li>
<li>
<p>No Data Control/Size Control</p>
<p>Here we should be able to use the techniques related with the Flink overflow in the &quot;Limited control over the overflow data&quot;.</p>
</li>
<li>
<p>No Data Control/No Size Control</p>
<p>This should be the most challenging overflow category to exploit. Its exploitability will be heavily dependent in the specifics of the underlying case. Nevertheless the approach is simple, the goal is to make use of the &quot;Limited control over the overflow data&quot;</p>
</li>
</ol>
<h1 id="future-work">Future work</h1>
<ol>
<li>Find a way to identify corrupted pipes in PIPE_TYPE_BYTE mode (should be a difficult task) or try to have Microsoft fix this important bug! (probably even more difficult task)</li>
<li>It should be interesting to escalate privileges through the SECURITY_CLIENT_CONTEXT approach. (challenging but should be feasible)</li>
</ol>
<h1 id="references">References</h1>
<ol>
<li>https://docs.microsoft.com/en-us/windows/win32/ipc/named-pipes</li>
<li>Alex Ionescu. &quot;Sheep Year Kernel Heap Fengshui: Spraying in the Big Kids’ Pool&quot;. https://www.alex-ionescu.com/?p=231</li>
<li>Corentin Bayet and Paul Fariello. &quot;Scoop the Windows 10 pool!&quot;. https://github.com/synacktiv/Windows-kernel-SegmentHeap-Aligned-Chunk-Confusion</li>
<li>@scwuaptx. https://github.com/scwuaptx/CTF/tree/master/2020-writeup/hitcon/lucifer</li>
</ol>

</body>
</html>
